\documentclass{article}

\begin{document}

\author{Wang Cheng}
\title{COMP 9102 Assignment 2}
\date{}
\maketitle

\section{Implementation}
\subsection{Import Data}
For the ColorHistogram.asc file, a line corresponds to a single image. The first value in a line is is the image ID and the subsequent values are the feature vector of the image.

In order to skip the first column, we used the \texttt{usecols = range(1, 33)} parameter.

\subsection{Singular Value Decomposition}

$U$ is of $n \times n$ size and $V$ is of $p \times p$ size. However, if $n > p$ then the last $n - p$ columns of $U$ will be zeros; we should therefore use an "economy size" SVD that returns $U$ of $n \times p$ size, dropping the zero columns. For large $n \gg p$ (in our case, $n = 68040$, $p = 32$) the matrix $U$ would otherwise be unnecessarily huge and cause \texttt{MemoryError} in Python. Therefore, we specified \texttt{full\_matrices = False} when using \texttt{numpy.linalg.svd}.

\subsection{Rtree}

One thing to note when using the Python Rtree is that it will generate persisted indexes on disk. Afterwards, the program will always read those cached files as indexes instead of building a new Rtree.

p\section{Experiment}

To run the code: \texttt{python multi-step-nearest-neighbor-similarity.py -q 0.01 0.06 0.3 0.5 0.01 0.04 0.03 0.02 0.000000 0.0001 0.0003 0.004 0.000000 0.000000 0.0001 0.001 0.000000 0.000000 0.0001 0.0004 0.000000 0.0002 0.000000 0.003 0.000000 0.0004 0.0005 0.002 0.0006 0.002 0.006 0.006 -k 5}. Here, \texttt{-q} is the query vector and \texttt{-k} is the reduced dimension. You can specify the same arguments to run the two-step similarity search program.

% 0.030629 0.038339 0.090007 0.031566 0.016984 0.029067 0.021149 0.073751 0.004963 0.000046 0.000006 0.000519 0.005483 0.000147 0.000205 0.000000 0.040732 0.241148 0.389802 0.007211 0.040938 0.017188 0.007146 0.000413 0.006833 0.000771 0.000829 0.000204 0.003648 0.007671 0.008066 0.005044

Evaluation is conducted by observing differences in performance on different choice of k. Here, the running time includes loading data, singular value decomposition, constructing an R-tree index, and nearest neighbor similarity search.

\begin{table}[tbh]
  \center
  \footnotesize
  \begin{tabular}{l|c}
     & \textbf{running time} \\
    \hline
    two-step (k = 5) & 5.7s \\
    \hline
    two-step (k = 10) & 8.8s \\
    \hline
    two-step (k = 15) & 12.3s \\
    \hline
    multi-step (k = 5) & 5.8s \\
    \hline
    multi-step (k = 10) & 8.7s \\
    \hline
    multi-step (k = 15) & 12.2s \\
    \hline
    linear scan & 1.3s
  \end{tabular}
\end{table}

\end{document}
