import argparse
import numpy as np
from sklearn.cluster import KMeans

if __name__ == "__main__":

	parser = argparse.ArgumentParser(description = "Using Clustering for Community Search")

	parser.add_argument('-k', type = int, help = "number of clusters", required = True)

	args = parser.parse_args()

	data = np.loadtxt('Graph.txt', dtype = int)

	N = np.amax(data)
	
	matrix = np.zeros(shape = (N, N))

	for row in data:
		# We treat retweet data as an undirected graph.
		matrix[row[0] - 1, row[1] - 1] = 1
		matrix[row[1] - 1, row[0] - 1] = 1

	A = np.zeros(shape = (N, N))
	for i in xrange(0, N):
		for j in xrange(0, N):
			if matrix[i, j] == 1:
				A[i, j] = 1.0 / np.sum(matrix[j])

	alpha = 0.1
	convergence = 0.00001

	for i, row in enumerate(matrix):
		e_u = np.zeros(N)
		for j in xrange(0, N):
			if row[j] == 1:
				e_u[j] = 1.0 / np.sum(row)

		err = float('inf')
		p_u = np.zeros(N)
		while err > convergence:
			tmp = p_u
			p_u = (1 - alpha) * np.dot(A, p_u) + alpha * e_u
			err = np.sum(abs(p_u - tmp))

		p = np.stack((p, p_u)) if i != 0 else p_u

	kmeans = KMeans(n_clusters = args.k).fit(p)
