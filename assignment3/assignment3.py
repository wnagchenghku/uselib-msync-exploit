import argparse
import numpy as np
from sklearn.cluster import KMeans
from __future__ import division

if __name__ == "__main__":

	parser = argparse.ArgumentParser(description = "Using Clustering for Community Search")

	parser.add_argument('-k', type = int, help = "number of clusters", required = True)

	args = parser.parse_args()

	graph = np.loadtxt('Graph.txt', dtype = int)

	N = np.amax(graph)
	
	matrix = np.zeros(shape = (N, N))

	for row in graph:
		# We treat retweet data as an undirected graph.
		matrix[row[0] - 1, row[1] - 1] = 1
		matrix[row[1] - 1, row[0] - 1] = 1

	A = np.zeros(shape = (N, N))
	for i in xrange(0, N):
		for j in xrange(0, N):
			if matrix[i, j] == 1:
				A[i, j] = 1.0 / np.sum(matrix[j])

	alpha = 0.1
	convergence = 0.00001

	for i, row in enumerate(matrix):
		e_u = np.zeros(N)
		for j in xrange(0, N):
			if row[j] == 1:
				e_u[j] = 1.0 / np.sum(row)

		err = float('inf')
		p_u = np.zeros(N)
		while err > convergence:
			tmp = p_u
			p_u = (1 - alpha) * np.dot(A, p_u) + alpha * e_u
			err = np.sum(abs(p_u - tmp))

		p = np.vstack((p, p_u)) if i != 0 else p_u

	kmeans = KMeans(n_clusters = args.k).fit(p)

	eval_matrix = np.hstack((kmeans.labels_[None].T, np.full((N, 1), np.inf)))

	labels = np.loadtxt('Labels.txt', dtype = int)

	for row in labels:
		eval_matrix[row[0] - 1, 1] = row[1]

	# purity

	for cluster in xrange(0, args.k):
		u, counts = np.unique(eval_matrix[eval_matrix[:, 0] == cluster][:, 1], return_counts = True)
		cluster_classes[cluster] = max(counts[0], counts[1])

	purity = 1.0 / labels.shape[0] * (sum(cluster_classes.values()))

	# entropy

	for cluster in xrange(0, args.k):
		u, counts = np.unique(eval_matrix[eval_matrix[:, 0] == cluster][:, 1], return_counts = True)
		cluster_sum[cluster] = counts[0] + counts[1]
		cluster_entropy[cluster] = counts[0] / (counts[0] + counts[1]) * np.log2(counts[0] / (counts[0] + counts[1])) + counts[1] / (counts[0] + counts[1]) * np.log2(counts[1] / (counts[0] + counts[1]))

	for cluster in xrange(0, args.k):
		entropy += cluster_entropy[cluster] * (cluster_sum[cluster] / sum(cluster_sum.values()))

	# NMI
